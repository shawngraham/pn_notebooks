{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ3nnb4gVnR4"
      },
      "source": [
        "\n",
        "In this experiment, we fine-tune the multi-modal IDEFICS Vision Language Model, following the example put together by Nitan Tiwari (https://github.com/NSTiwari/Fine-tune-IDEFICS-Vision-Language-Model)\n",
        "\n",
        "Working this through, I created training data by hand. But this is also an situation where a larger model like Gemini 2 might help you generate training data; you could give Gemini 2 an image of eg a context sheet and the following prompt:\n",
        "\n",
        "system prompt: You generate high-quality training data for image question and answering from scans of archaeological context sheets. It is important to work with highquality extracted text. The meaning of the texts in the scans can be deduced from which boxes the text was entered. Stratigraphic relationships can be inferred by the placement of context numbers in the rows of boxes; the present context will always be in the centre, and other contexts will be entered in stratigraphic relationship above or below as appropriate. Data should be returned in csv format: query, answer. Like so: What are the general easting and northing for this site?,\"['443281.71','258449.217']\". For each image provided, generate a dozen highquality questions and answers.\n",
        "\n",
        "It's worth exploring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDgLCDXXAByz"
      },
      "source": [
        "#### Step 1: Install libraries and dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NWM6sYv45s1",
        "outputId": "18aa8bb2-7fc3-4075-f444-fef3248bb389"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q accelerate datasets peft bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRyfCP_gNTUC"
      },
      "outputs": [],
      "source": [
        "# drag and drop a zip with your images into the file tray.\n",
        "!unzip your-images.zip -d training_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9PcEaJo55tv"
      },
      "source": [
        "### Step 1. Make Your Dataset\n",
        "\n",
        "Drag and drop your csv into the file tray. You should have:\n",
        "\n",
        "```\n",
        "|-training_images\n",
        "    |-image1.jpg\n",
        "    |-image2.jpg\n",
        "    |-etc\n",
        "|-qa_pairs.csv\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GHcRVoVF-Br",
        "outputId": "63ed0d84-bb57-4d44-ace5-e9bbbee16ba0"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict, Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "TRAIN_SAMPLES = 1000\n",
        "TEST_SAMPLES = 200\n",
        "TEST_SIZE = 0.166\n",
        "\n",
        "# Define the directory containing the images.\n",
        "train_images_directory = '/content/content/training_images'\n",
        "test_images_directory = '/content/test/'\n",
        "\n",
        "# Read the CSV Q&A text.\n",
        "\n",
        "qa_text = pd.read_csv('/content/qa_pairs.csv') #remember, 3 columns id,query,answer\n",
        "\n",
        "\n",
        "# Get the list of ids from the csv, which we'll use to match filenames\n",
        "ids_from_csv = qa_text['id'].tolist()\n",
        "\n",
        "print(ids_from_csv)\n",
        "\n",
        "# Create a mapping between ids from csv and filenames\n",
        "image_paths = []\n",
        "for file_id in ids_from_csv:\n",
        "    # Try to find the image in the training directory.\n",
        "    image_path = os.path.join(train_images_directory, f'{file_id}.jpg')\n",
        "    if os.path.exists(image_path):\n",
        "        image_paths.append(image_path)\n",
        "        continue #move on to next id\n",
        "    # if it's not found in the training directory, check the test directory\n",
        "    image_path = os.path.join(test_images_directory, f'{file_id}.jpg')\n",
        "    if os.path.exists(image_path):\n",
        "        image_paths.append(image_path)\n",
        "        continue #move on to next id\n",
        "    # Special case: check for summary.png in training directory\n",
        "    if file_id == \"summary\":\n",
        "         image_path = os.path.join(train_images_directory, f'summary.jpg')\n",
        "         if os.path.exists(image_path):\n",
        "            image_paths.append(image_path)\n",
        "            continue #move on to next id\n",
        "    # If none of the above, raise error\n",
        "    raise ValueError(f\"Could not find a relevant image file for {file_id} from csv id\")\n",
        "\n",
        "# Create a list of other columns such as id, query, and answer.\n",
        "ids = ids_from_csv\n",
        "#queries = qa_text['query'].tolist()\n",
        "queries = qa_text['query'].tolist()\n",
        "answers = qa_text['answers'].tolist()\n",
        "\n",
        "# Create the dataset dictionary\n",
        "dataset_dict = {\n",
        "    'id': ids,\n",
        "    'image': image_paths,\n",
        "    'query': queries,\n",
        "    'answers': answers\n",
        "}\n",
        "\n",
        "# Create the dataset.\n",
        "dataset = Dataset.from_dict(dataset_dict)\n",
        "\n",
        "# Cast the 'image' column to Image type.\n",
        "dataset = dataset.cast_column(\"image\", Image())\n",
        "\n",
        "# Split the dataset into train and test.\n",
        "split_dataset = dataset.train_test_split(test_size=TEST_SIZE, shuffle=False)\n",
        "\n",
        "print(split_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSAQsTa0Xe2C"
      },
      "source": [
        "#### Step 2: Push the dataset on Hugging Face Hub (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "a1722f396e534778880d380562fc3f95",
            "bffc549045ec448c96ffdc78783107d6",
            "4c62239c0ec54c2d81931f98d1651605",
            "679a70e99f6b4ecdb570e8fc9f339b16",
            "0f489293eae54e8e9d29c73de0bbe921",
            "825e31970c5a489592bf38b177e55cbb",
            "e39f0a7d3c4247c8bff8fc107b5c72de",
            "31686426f07a4153b8b6780df8fcd168",
            "4287ca8d77b24622bc4231989ab86655",
            "62a0e1e326814efaac93308f79e23d13",
            "2c5db5246b5d45fc973789f3ca4f90c2",
            "c1598fe252164d99b28a1a24c7c90d47",
            "a942c554231c4858873070235a953f31",
            "3a7e96ef97b54fc782f8a5659ff51bb6",
            "195e363118e14898bef2253bd60d22dd",
            "42870d6e48cc46d4a1e9b2603220bd89",
            "3efbed3cf6df4302bf49b01dcbbb4c21"
          ]
        },
        "id": "2FT1Mg5ZAKTy",
        "outputId": "8d91f726-03cf-4a0d-b150-17f8619bb0e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1722f396e534778880d380562fc3f95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "fb8a6a685c2e4f09a6e590f2037d294d",
            "9a233bbcd63144d3b89856879b0f9b5e",
            "8bfd159822d041039b7ddd074e9d060c",
            "64093b3286c2477585bcb1d8eb38600e",
            "5f4069c1284a419781d20e21dae40188",
            "fd81f8bbbda0466783a329b2da2b6555",
            "9f386ce5c8ec4c9ba2f64b494e0445c0",
            "a4e0f31fed2a4a83abb4adf1d9f03c01",
            "9455b7b1d1f94cd2a4d7fa928ed8609a",
            "9af707502f24417ca9b0b897522bb2ba",
            "1be2ce6b7e23469d972487714f9b5508",
            "acfdfa3d2bf04f31981df39bd2fdfe14",
            "ea9c526d1c374b94af65a3eff069d3f1",
            "138512f192304ada80888e27ce388a13",
            "bdb2bd33b0c54cf2891727f9a14f6cd4",
            "2a56f1bb803f4440bbdfa0ce442bbf02",
            "9fdeb9c6241d434db72ba40ec107cdd7",
            "7581f042b08b4c64b68fffbf8e85ea24",
            "9fffdf84312c4643804539840a4150c8",
            "a5748e9f513342b78be445ae62b6a621",
            "d98a3e44c1684235a88dce83f0ca130c",
            "070c93201ade4e2a8b96a2dc6fbe4a7f",
            "152990e4d618434c831400365da982fd",
            "e61fd4b8535a4163a83a2bb836a1741c",
            "c9f8149fc7344a5d9065c5317a07c187",
            "3a4ad27b22974cf99d9a71bd6d58059a",
            "add281f3fda74e679a8c9da44fe1a338",
            "7ed344691d164ab394b98169a00d8682",
            "b04c6ec7ab03486faa44316ae18e692b",
            "b1ea666ddef346bda824ab3264e25443",
            "01bc89b0dffc47f9a096db249586c27a",
            "3ad1a8fc1b3240ee81c05d3d8f406011",
            "bbe715122d1044849b1a1f8131eaae12",
            "58d0d920abe1428ab44e13c7f3f7d4ff",
            "5c285def66174c42982693e6853543cf",
            "8b637ec04fcc4980b74d5e7b00ac03fe",
            "b27aa095022e4d5391906baee11b12c7",
            "cd18f996d53e40b09d9a74cfc5a7f23d",
            "90815d89bfbb4445b5a721f7c28412c7",
            "0ee6e52199804034a481252e489a343d",
            "8e44ed6664f74a6e86a1c62e78dcd1d1",
            "74688137fe2a4cfabe5a31d98da1a626",
            "67805247ff0f4686b932f9157a342626",
            "3eaf64c4022543ffbdf93a727edaab74",
            "9556a4c494a04fb48709b7491da57fa3",
            "29ea79a6c6414958b23f89471e7deee9",
            "258ca3a6e2a745f78042c55aaa27bc89",
            "a645e2e7fa064a56b776d07bb1744945",
            "00f2fa207bac4ed1aa08961fdee690b0",
            "980d9aa0ddc749eb947ba9bdaf7e329e",
            "32739606461947e7a6a8ee9ab1ab7240",
            "4a437ec7ae4b4d7289358ec8621a65f9",
            "c9c269055f9c4565ad97fe6fd94d803f",
            "42abcb09f74b4311a822b3c7da94afa0",
            "ce4e647807dd40568152a2cdcc4f9490",
            "59d14900da2a4495bece2de964925948",
            "e32f1c8863fb49af80defe353b9bffef",
            "210e788eb336434bad3f5b5c1bae4c5e",
            "d571fde1fe11424497b609ae6d279c1a",
            "c9a3506913c5467e8386cd71e7b4d428",
            "e5cfe81c8cec46d2a3815c549a154fbe",
            "959d9dd2b602422d9545785e9a796b75",
            "2d70f9ce14b54e75b73fc76ffa75b016",
            "cf6d6561313a443ea163c1035ec883ff",
            "9835b312468f45c08c70eddef9b3f8ce",
            "aed77ff0e845472c8f414c236cfff901"
          ]
        },
        "id": "aFTJuJgeXksh",
        "outputId": "469f60ac-bac6-4aad-bfe4-0106911fe588"
      },
      "outputs": [],
      "source": [
        "# change your-username!\n",
        "split_dataset.push_to_hub(\"your-username/DocumentIDEFICS_QA_archae_test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43QQ8Ak9ZrEJ"
      },
      "source": [
        "#### Step 3: Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "b44a985e1f5548368b32ff5e8ffba853",
            "61b951fc81e442beb99d20f41e21df53",
            "d065263c2bc04714abec9c080b88291f",
            "76e9ab9fd3e5490184e93a874564499d",
            "498e3bb70f2d42ef85b969a48c82ecfe",
            "61a0751fb7eb4c4f870f1f8d1ccc504f",
            "b7efb59c4f4a46e0945cb4fc62e3464e",
            "cf01231b22aa4dec86434a8baf2a68e3",
            "58859edb9ef342f8b7e9658741b0e3b8",
            "cfb90842ce8d440db0ef773876d7f32b",
            "e9437c3aba02411cb5bc6e288108714f",
            "04bd89cf5edc418b955d73b13d73dc8a",
            "1b8cf88b052b4faabd861db3fb36b689",
            "993d611b51d24137b08c4c4666f9087c",
            "9e6c9dc056d541f98c61be762bfe0e9e",
            "790ab70149184c5381a074d21c57d021",
            "f824958163f941538d65c01e52d72276",
            "c728f2a8e8964fe595bce25d85e8c847",
            "6bb3462578c24bc1bd55a918095f6d92",
            "5c2abeac02ec4fe08b524ed6324cc439",
            "0626528561b54faa8a004e9cfe0c1b98",
            "2f2cc87192a24501837b3c944dab35c9",
            "854038563d01443686a2595336b87d23",
            "05ae3b08c9ba4a5284ef85f4099e927e",
            "69e285adfd904b80b017d2ba3978f4b6",
            "ce72787615084bf6a2731f0da3fa2960",
            "623f37fd04c841519393a9f26414684e",
            "d590d40877174a88b4b248f4dfa38673",
            "38dbb517aed24419a1bf8f831ef5aabc",
            "6f93e86f6bb8422dae417daeee1cd483",
            "74590cab42674980ba608e3dbe00778e",
            "0d7056239204402f85da94a97b96fa38",
            "255c7249322449dba805d8b9891476f7",
            "451dfd2d1ed048b39bd5ec3dd2a742a8",
            "9f4cc63419e647c18882acb8d8592ace",
            "a4ff283335c0430287188b9dab389a7c",
            "a8a9463d64db4c66a054c834517ad578",
            "60866a003aed4a3698c6969d33406c46",
            "4ea79b1d76eb4c9695e1a3577c4bbd38",
            "55af00b491ef42e7901b115d2527614d",
            "23c8fbbc6fc649438512df9e7a73c128",
            "3bff78e8f71e4095880ea1eeff87edcf",
            "fa5df6382601473fbfa66ce0bc1dd269",
            "4523bf01751448fea950c829d7dca0af",
            "cfe37b463e534c5d83009f0d57a6bc79",
            "5a38ad4af1f8409d92caef8bd2224fc4",
            "d3edcc37a112428cb711542daa64aee6",
            "f5e71854a25147209175f43574e1547a",
            "bc07a0d0d36a4cba90a0f42c6443dd50",
            "84245c80052842018225b9211d6b161e",
            "46dddd7d7a114f7db0c0feaf164efc2d",
            "4418b3e08b5947ef8287dfce48cad348",
            "724ea69fba5c4365b53a4b66b9f26013",
            "14fbd694b94a4b6a8a20ebc3a9fd0bba",
            "4dc072bfec3e4a27a65cda1cd426e729"
          ]
        },
        "id": "LMd1OfYMZqiR",
        "outputId": "7e8e9ba4-d46c-4a51-9abe-c0ff65ef05a4"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset(\"your-username/DocumentIDEFICS_QA_archae_test\", split=\"train\")\n",
        "eval_dataset = load_dataset(\"your-username/DocumentIDEFICS_QA_archae_test\", split=\"test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZOAgM75Z4Li"
      },
      "source": [
        "Inspect the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEI2JmcvpVNs",
        "outputId": "4d88a48c-5d55-48a7-e55b-547de12342c7"
      },
      "outputs": [],
      "source": [
        "# this will return the first row of your training data set\n",
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "k2Cbxd1XZ7r5",
        "outputId": "8dce36bf-1d83-4e52-9b80-cd3b4ec8ac72"
      },
      "outputs": [],
      "source": [
        "# this will show you the first image in that first row\n",
        "train_dataset[0]['image']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Rn2P2SAI4C"
      },
      "source": [
        "#### Step 4: Configure LoRA adapters\n",
        "\n",
        "This is a particular fine-tuning strategy. Don't touch these cells. Run them, but don't modify them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "f043e43c771e48fe8e32e36c8ff73320",
            "1e8d364a9b9c4eb1a59d41098d45866f",
            "8dcc3264ec4e4016bfda9a6f6f6d54cd",
            "834413019afa412898e77b56ea15e195",
            "2096397d252241dca0307d6c1f783cad",
            "bde352facc7b4b02966d0f21267dca22",
            "e2e17f8377a94befa1982ba89627b612",
            "05602abd6c374a97917e46cdf2c70c68",
            "74b44ba2492d4904be1b72a8e22352d6",
            "8e64459f905b432db089fd08187b3014",
            "42ccfbadd9434164bb91b0eaeae56cde",
            "57fd43a4c9b3407f971ab1c5ef44c335",
            "edcdd1fce0694e1d82d68540c6802ba3",
            "8d288339d7de4f34b91b3d5f28af7f78",
            "ae1827de8ebd4e74971a2dbfcdc37cb1",
            "463c7c38004e424b9159a43a4aa836eb",
            "b5dd9bfb57594bd49a350afe1428c641",
            "76c07aa2768745e39fb96ccd8322f910",
            "21de96f3572a4fc0a88a06f2d9cf812c",
            "e2f20d3c7f32436795ed880990d06ce1",
            "370b8ce0e9214f9d8bd8b7cb823b2e86",
            "ac7fbc8168ae4e61990db42cb02ffe02",
            "2fb9a851305446c5ae885401ebd0d137",
            "8995f45aba5a4515a6897109dffbadc4",
            "cedf013337c9474796f7a618132559b7",
            "e8a19f1e6d354325a42070b6466c5269",
            "95532af9b55e4544aaf71f877db43f01",
            "66c2013ad5bc4012bb95d8fe0a6d8b93",
            "396e1c35a5974d299cfa5437dad97e2c",
            "bfda1e5f5b7542c094189f1f31afd04b",
            "555289022d024b21b67aa41fa1578e54",
            "75d11bce6ddc4c349a9f51157d6b8970",
            "eb7874520f2e463fb7b31c70c9032bf9",
            "34657affc46f49cea176a2ab0d5ed610",
            "53d749b835ca4450979a379941a4c39a",
            "8b478c9afa0545c8bfab1a708a42924a",
            "328590fde6134be990c4d092cff9322f",
            "a3009063337145ca918f69de498cf0ed",
            "249578046d434750b98bfda22ce14139",
            "917ab9cf8d7d447dbff8108969fc8e62",
            "b8c4c0cdb0254dd0b3ba10c7fc39b05e",
            "051a657a824e4c198e69b2fc990b4c85",
            "a2129fbfe0534559b646642909dbdd14",
            "856faadc95124c7eb1bd50137d862af7",
            "18574006c9e34ce399e116d5e838ad5f",
            "8522c33c514849cf944d6f456badc1b6",
            "f41acce4c40447ed9250a2bde4dad4fb",
            "6d5e4161c47b4851987711635b862b18",
            "238e5e60c45449fa90ceca30e2c0431e",
            "ce38bd32fbe846d3815e7ef90b93e687",
            "491e60f8caee4f42ac03b856ebbb0e06",
            "e8b5028cee6145c19375586fd64c900d",
            "15022ea69c0c4f3e8d9bbd84f004b92b",
            "359820d29a5f41309980d4572d247bf2",
            "1ed7df204ae242c497e30ff651a00609",
            "32f38db3e4194f878e36a3c40d8736ae",
            "c5c9ce311e1c41b4bc22f54aeebf6a77",
            "5eea09a1af7e4b398a39f5434d5c095a",
            "8965a57c7ac849c9b11bf92bebcc8669",
            "8dee9fcb23864828bb2ae157c557b478",
            "a284320214754152a03948da0b462896",
            "65de99b134e549e7ae05eda321414adf",
            "39feb0fcdf2e430697fe0e29c813910c",
            "c27e415a92aa41d8a12fbd854f977c45",
            "c74f80274f27424185d2d40d052b6a17",
            "88af5489a79e477a93db82f7f6b90048",
            "199ddb2f1b34471c99119edd4fccb1c9",
            "11b113e52e6640ab9c33ccd8864cac48",
            "eb69910ed807468382d83b6c19d4bcf7",
            "9c3fc94850884d979e8c278fb8a13b63",
            "74422951c62340e193f51f7349d17d5e",
            "42cc31d3ba2c473ca8bf0cf6de79dec8",
            "d54ff39d1be5442fa003d9746f0a229f",
            "c5553855ef634dc48772e0a0a59f28cf",
            "d0d880699d274a3197be4b956da88339",
            "b039ada00b2143f1b90b91699139196d",
            "fa02b0309d594174957c41f9caecd0ef",
            "7001ebb72efa4b0e87140463a7219533",
            "7fc296da72164672b3b52a9fd3baed19",
            "2131800c311e4447a046afa4d2aaabb9",
            "d297fc13af354fb89a7ce1c2024c40b2",
            "317a81bf99634250bbc3fb31ba16fefe",
            "cd4e1ff32c084273bce56e12746a1df5",
            "fc9fb403b15f41328bb7b8f9d860168b",
            "3e010d0b91bb47ac903c260276ce4721",
            "bb3e5140440e48b6966656b0e127992a",
            "a1cc8ab74d06453fab3cf9444a11e474",
            "ed1967c3ce9a4426bf19397112a49185"
          ]
        },
        "id": "dapyMHIsAT1E",
        "outputId": "b8c602ee-988d-46a7-cbf3-6be2e0cb747e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from peft import LoraConfig\n",
        "from transformers import AutoProcessor, BitsAndBytesConfig, Idefics2ForConditionalGeneration\n",
        "\n",
        "DEVICE = \"cuda:0\"\n",
        "USE_LORA = False\n",
        "USE_QLORA = True\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    \"HuggingFaceM4/idefics2-8b\",\n",
        "    do_image_splitting=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419,
          "referenced_widgets": [
            "dbdb6c565a404417ac422bada23a329f",
            "6e29a68e36a34ea7a73648713d8bbf88",
            "b1a262e7af62476d865d1a164f941d8c",
            "4878d545eec84ee0b9d0e41caa132bad",
            "d9faa3b2143647248bb514e8a5aebe05",
            "3da211eeccd84dcbb012e02b7264cc55",
            "4ca5f2751c6144d4b483fcf7ae6d2058",
            "836cba55930c4b7e99c41b67ca716ed3",
            "494375f6bd3549309e5cf18b8cd9494c",
            "0f854dd6b5c141ecaf5733b3ce649766",
            "fc806879dac5442ebf7b455549f498c0",
            "56196c89dc2d49c7a34ed378ae00c8c3",
            "699bbda8154645b3973789058a846b40",
            "e9edda4351a14495b876ed983df14cd8",
            "0692c64f48004cba8538092e43ffdfda",
            "c2852d98e2434c4ba9b29321f8407f66",
            "7d4e58fc6a514f729bdd8d7ec0c4ed3a",
            "32e5616ed95c4fc6a68b860dfec5e1cb",
            "0e92c7617e0148c9b4f4b06348fdaaec",
            "25478176e00243e0a721b756e65b2c12",
            "7c07ad1ae73a442292b754221123162b",
            "5516f6056f7a4b7b802e7167560d7376",
            "32a432902b104a08be3f51d12c02c5ac",
            "70d3dadb16b443e6a8cb20276e9b71e1",
            "36e439d821f448cb83665346072fbfb5",
            "751e54c9eb61488a98c5a98657f8920e",
            "91f6fee644da4e49be8e73342252b296",
            "d681048d8904488caa80c0d59ec6b1d6",
            "60a1e04b5fc1469f8da90c666a094765",
            "99ef159cc3fb417ba654ee464fccd12e",
            "865a71533f574b8a81c1e80998dbeec8",
            "712310afc5f54d288a7da828f11979af",
            "51eea2c2db5a4136b49abdd5058b1ac4",
            "c1e3a8e642fb486fb5474a7a4db0945d",
            "3bba6108a5bc4a81a8586f11c6f56257",
            "4bca3e1798d84323898023918ff74eac",
            "60ca2a97c6a446f0960a965fa798faff",
            "e851f80696624a8c8308505946ec79bd",
            "808a726df2074624b88f0f905044b267",
            "fa15cb300d1b4200a1fdc26fcaff7647",
            "61b497e1808f4299bba9dbd2befc068d",
            "0d21ba81544a4315b340cba20a828d1a",
            "246ccf98a904471bbd4fe216993e1f60",
            "598799afd256429181249b1bc411a620",
            "4f2039ea5c3f4a32a7353b9d34eccc42",
            "3b2219671f5d4250956f28c84670ea78",
            "3dc0730fed674422a93ac21069763277",
            "d93f91bee5bb477d8cdfec83e2da251f",
            "ce0a592ee42e48aa95cacdb094f1658d",
            "79cf15b52cd04c539e023237744146cb",
            "c23c6881d74745358d04dd3063d9cf94",
            "b20bc57cf0f6479ea733981ece027a02",
            "c996cfce1b5f442187ce127f657cfae0",
            "eec25f2dfaaf4883ac5400b0a3a453e1",
            "bedfe1fcb91b4bf5b2e214c7ce233bb8",
            "4fd2fc79b36b4135a4414d7a626c7c1e",
            "4b5656db1d914082acb947a6fed2a02c",
            "bd05d794f2f04bb4ac34456729e92adf",
            "bad46f04ff814eee90858fa739da638e",
            "043696ea11cf44da9d8e40944c844006",
            "04693f80974b4945af1d05bc5bf79486",
            "2fc321346f52404d907e94d58fb60a51",
            "0593f30102124cdab504b603fbfd14f4",
            "a305a8d694094ceaa14a22a00bda3fdd",
            "a3cb24f5e2284159950cc37450732327",
            "5bc77f7c517741948f5ad1fe0bf6f882",
            "660462021c5c4192bd2e5940cb0c4c7e",
            "7cb11b73f070482baae5661ed63dfc09",
            "2d7c114a500d4359bd5b14a695509765",
            "77b1797297b645708d2f6fbafcd768d9",
            "ecc53e9c49f1416aa4b5ca1a19860a79",
            "56007e47229448dc8a566a82eac84920",
            "84ae8af9b1d341cbbca1f3b755ea87b2",
            "932f54efe7034c85b6389f913ecd998b",
            "56c756f4f9a54f46a6600ec208b68db3",
            "80aa033884754e7c9358877055114f7c",
            "02219bbe237e47759ebec9f60c4834c4",
            "3eaf8f1b07d443a5911436db4c05cd7a",
            "360f5ca50a0b41ceb3868ac2db94bb47",
            "272777f98f0c4298a77d5d422d9b6372",
            "95a5aaac51944646ac7cfaecaebda9dd",
            "178505224ff74b2589112940173a0462",
            "26b0af9c8a3e44f5bd5092a6703b7469",
            "0b697a44fb1f4b61b04368734fde6f17",
            "fb43fa660576444cbb89fb1a9f575841",
            "76275900055d4e4db8e46b63eef3ec91",
            "14281d032bde49c19ac328ffb7170e56",
            "b1db299ac2e14e848fde387c4b200acf",
            "adce1051bd73496da82e4ab938b2fdad",
            "013d49dbb7424800b7885f087ab6c2dc",
            "987f904a3c834adbb4c15a13df639c0b",
            "2226aa94473b4b6f82d4fcaa8f6555ca",
            "d0221e655a8b4fb68546e0474ac2886b",
            "f761687a2312487abc5af30abf1dd2f1",
            "7dfc06e0bdfe42108e9579af889de85c",
            "e4efc8ac265a4f7a897ff914a6ff0e4f",
            "e497b4eecdcc4aa3866fc63360a573b9",
            "770244a79a3d4e4485f27fe3ba88019d",
            "b7aeb16a2abe4f2b8039c4b280b96c0e",
            "6111a61dc3d74139baa0ddeb606d5ba3",
            "ab0ccd9371ca44708de1ca2fef32927d",
            "8f92ed38f70f452183559e23cabf9bad",
            "9ace60c81eda4880abef2edc336820da",
            "48d0066bd13a4c58a6a8ecd86c6956e4",
            "125d2db5a91d4de48ddf5cb1feef653a",
            "ef2087aef9284567b82b9c53471ca05a",
            "4d29499f4d5d43989c1734b95dd9d714",
            "992c0c0af79d4235b536dddc288dd726",
            "04f02e4023bb469f83b298241a2cb922",
            "c3f9a5ebb31648c0a722056e536651ce",
            "83eb5999b2e642d3b105d01e9a35f98e",
            "673695de38f24ac58987af043b0ef4df",
            "e28bef6123864428857364a253399663",
            "5c93a80b4461487fb3f252326c383032",
            "82f779d3473e48959c1e7a8a051bc09d",
            "8172d1a470c04d3da59daf37a33f2c99",
            "478d6f4502e549f1b6f85620cfce610b",
            "493603249824404398d20b5354583ec5",
            "85f85177d8cc46ec96007557426ef77c",
            "5da52c7b55c54eee826bc3c21587679b",
            "e07112e954b848909b5efc26530eeae9",
            "6d64557b66c24985842ab07c18d26ab1",
            "ee5afbbd9f7d4dc7be58e62d01641cc5",
            "d0a7df175b9f4444a6d0cbd261529cb6",
            "7da5c9a983254aa5bdecb80e0045d3b3",
            "ca057d6237954be7b310bfea0978bf8e",
            "c55fc130c7684681a63fe44c4f49a63b",
            "90ed08635fc142eabb17978e91cd96c8",
            "a5ca690830a2457fb099b45ae1d93fab",
            "a71dbb7adbd248c7b515f42b6af12a17",
            "0f8df67b547748f382e67c55175dc7a2",
            "6eb7e8eab2c94da48b3512f4a4c93d82"
          ]
        },
        "id": "n1_LkYWTrAat",
        "outputId": "78b25375-ac5c-4c9e-a19e-5badd3bdfd0a"
      },
      "outputs": [],
      "source": [
        "if USE_QLORA or USE_LORA:\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=8,\n",
        "        lora_dropout=0.1,\n",
        "        target_modules='.*(text_model|modality_projection|perceiver_resampler).*(down_proj|gate_proj|up_proj|k_proj|q_proj|v_proj|o_proj).*$',\n",
        "        use_dora=False if USE_QLORA else True,\n",
        "        init_lora_weights=\"gaussian\"\n",
        "    )\n",
        "    if USE_QLORA:\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16\n",
        "        )\n",
        "    model = Idefics2ForConditionalGeneration.from_pretrained(\n",
        "        \"HuggingFaceM4/idefics2-8b\",\n",
        "        torch_dtype=torch.float16,\n",
        "        quantization_config=bnb_config if USE_QLORA else None,\n",
        "    )\n",
        "    model.add_adapter(lora_config)\n",
        "    model.enable_adapters()\n",
        "else:\n",
        "    model = Idefics2ForConditionalGeneration.from_pretrained(\n",
        "        \"HuggingFaceM4/idefics2-8b\",\n",
        "        torch_dtype=torch.float16,\n",
        "        _attn_implementation=\"flash_attention_2\", # This works for A100 or H100\n",
        "    ).to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNpTw832C-or"
      },
      "source": [
        "#### Step 5: Create Data Collator for IDEFICS2 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1laLAXLN47c"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import ast\n",
        "\n",
        "class MyDataCollator:\n",
        "    def __init__(self, processor):\n",
        "        self.processor = processor\n",
        "\n",
        "    def __call__(self, examples):\n",
        "        texts = []\n",
        "        images = []\n",
        "        for example in examples:\n",
        "            image = example[\"image\"].convert(\"RGB\") # my images are greyscale\n",
        "            question = example[\"query\"]\n",
        "            # Check if the answer is already a list or needs to be converted\n",
        "            answer = example[\"answers\"]\n",
        "            # if the answer is an integer, wrap it in a list to make random.choice work\n",
        "            if isinstance(answer, int):\n",
        "                answer = [answer]\n",
        "            elif isinstance(answer, str):\n",
        "                answer = ast.literal_eval(answer)\n",
        "            if not isinstance(answer, list):\n",
        "                answer = [answer] # handles the case where answer is a single int or str\n",
        "\n",
        "            #Now the answer should always be a list\n",
        "            answer = random.choice(answer)\n",
        "\n",
        "            messages = [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"Answer briefly.\"},\n",
        "                        {\"type\": \"image\"},\n",
        "                        {\"type\": \"text\", \"text\": question}\n",
        "                    ]\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"assistant\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": answer}\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "            text = processor.apply_chat_template(\n",
        "                messages, add_generation_prompt=False)\n",
        "            texts.append(text.strip())\n",
        "            images.append([image])\n",
        "\n",
        "        batch = processor(text=texts, images=images,\n",
        "                          return_tensors=\"pt\", padding=True)\n",
        "        labels = batch.input_ids.clone()\n",
        "        labels[labels == processor.tokenizer.pad_token_id] = -100\n",
        "        labels[labels == model.config.image_token_id] = -100\n",
        "        batch[\"labels\"] = labels\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        return batch\n",
        "\n",
        "data_collator = MyDataCollator(processor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyTKfJgHFPBL"
      },
      "source": [
        "#### Step 6: Setup training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwlK3evVQu3B",
        "outputId": "010f6766-d68a-4103-93db-f24cec7b5e3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1573: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of \ud83e\udd17 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"IDEFICS_DocVQA_1\",\n",
        "    learning_rate = 2e-4,\n",
        "    fp16 = True,\n",
        "    per_device_train_batch_size = 2,\n",
        "    per_device_eval_batch_size = 2,\n",
        "    gradient_accumulation_steps = 8,\n",
        "    dataloader_pin_memory = False,\n",
        "    save_total_limit = 3,\n",
        "    evaluation_strategy =\"steps\",\n",
        "    save_strategy = \"steps\",\n",
        "    eval_steps = 10,\n",
        "    save_steps = 25,\n",
        "    max_steps = 60,\n",
        "    logging_steps = 5,\n",
        "    remove_unused_columns = False,\n",
        "    push_to_hub=False,\n",
        "    label_names = [\"labels\"],\n",
        "    load_best_model_at_end = False,\n",
        "    report_to = \"none\",\n",
        "    optim = \"paged_adamw_8bit\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9weQsmSmQ3B5"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator = data_collator,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = eval_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIeacijNoRYy"
      },
      "source": [
        "#### Step 7: Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "vwsjM_FnFe4r",
        "outputId": "ecaaaa1c-e3af-4eef-ac8b-cf24b707b4de"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX6KvkGKoHPT"
      },
      "source": [
        "#### Step 8: Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BNcxH2Sq-VR",
        "outputId": "77d50982-24da-458b-852a-eb8e7e5695b0"
      },
      "outputs": [],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LuWP89foV_u",
        "outputId": "85c9afcc-e84e-4cb6-95fd-66b5d7b904ee"
      },
      "outputs": [],
      "source": [
        "test_example = eval_dataset[3] # ie, the 4th record in the data held back for testing\n",
        "test_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "o7hZ77m_ocDV",
        "outputId": "0d432983-d8b0-4c0f-9ace-b1a03cc76c0e"
      },
      "outputs": [],
      "source": [
        "test_example[\"image\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1oW2J9Xodpc",
        "outputId": "ed870af0-e9c5-4d47-a832-3537d557beab"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "image = test_example[\"image\"]\n",
        "query = test_example[\"query\"]\n",
        "print(query)\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": \"Give your best answer.\"},\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": query}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "inputs = processor(text=[text.strip()], images=[image], return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# Move inputs to the same device as the model\n",
        "inputs = inputs.to(DEVICE)  # This line is added\n",
        "\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=64)\n",
        "generated_texts = processor.batch_decode(generated_ids[:, inputs[\"input_ids\"].size(1):], skip_special_tokens=True)\n",
        "print(generated_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW4ELMUEogAV"
      },
      "source": [
        "#### Step 9: Push the model on Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGoRhVPW20Op"
      },
      "outputs": [],
      "source": [
        "#push the complete model:\n",
        "from transformers import IdeficsForVisionText2Text, AutoProcessor\n",
        "from huggingface_hub import whoami, upload_folder, create_repo\n",
        "\n",
        "# First, save the model and processor properly\n",
        "def save_model(model, processor, output_dir):\n",
        "    \"\"\"Save the model and processor with all necessary files\"\"\"\n",
        "    model.save_pretrained(output_dir)\n",
        "    processor.save_pretrained(output_dir)\n",
        "\n",
        "# Then push to Hugging Face\n",
        "output_dir = \"IDEFICS_DocVQA_1\"\n",
        "repo_name = \"IDEFICS2-DocVQA-fine-tuned-PALP\"\n",
        "\n",
        "# Assuming you have your fine-tuned model in a variable called 'model'\n",
        "# and processor in a variable called 'processor'\n",
        "save_model(model, processor, output_dir)\n",
        "\n",
        "# Now push to Hugging Face\n",
        "username = whoami()[\"name\"] # you don't have to specify your username this time, since it's reading it from your token\n",
        "repo_id = f\"{username}/{repo_name}\"\n",
        "\n",
        "# Create or get existing repo\n",
        "repo_id = create_repo(\n",
        "    repo_id=repo_id,\n",
        "    exist_ok=True,\n",
        "    private=False\n",
        ").repo_id\n",
        "\n",
        "# Upload the complete model\n",
        "uploaded_files = upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    folder_path=output_dir,\n",
        "    commit_message=\"Pushing complete fine-tuned model with all necessary files\"\n",
        ")\n",
        "\n",
        "print(f\"Successfully uploaded to: https://huggingface.co/{repo_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SgAgPy2ovdm"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import whoami\n",
        "from pathlib import Path\n",
        "\n",
        "# Output directory.\n",
        "output_dir = \"IDEFICS_DocVQA_1\"\n",
        "repo_name = \"IDEFICS2-DocVQA-fine-tuned-PALP\"\n",
        "username = whoami(token=Path(\"/root/.cache/huggingface/\"))[\"name\"]\n",
        "repo_id = f\"{username}/{repo_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "cd676368f66541b78e8d5422bb811289",
            "8fdaaf963e1c4732adad1a10046bbd48",
            "70a96d96573f4d349e41e009565f1433",
            "007d82f6e0b84dffa3b796c05fad6872",
            "4189d380b0604dcb8625f41bb2fc81d3",
            "1cccfc20b6134d829e51d0cc757cc60b",
            "e2de6dc9a55b491498853c344ba75d42",
            "090581126ded4a9eb027856ddf88d467",
            "9088399b430f407eb0beed68d5232fbe",
            "36a968864fa748f2a633d9b07a3fb9b8",
            "4ec781671c614013859c0eb026736871",
            "f8b85ad115c54a05bb554ddecf1e1412",
            "eed6efb5bacb411fb6e9197739ea7ec2",
            "39ad2136059b4120a1ecc70b8c66c7d0",
            "9934acb6e9b049bfb76b4a86ee3c8d2b",
            "999f7c69a8a443409f41df70abb499a7",
            "0f63034488a942849b5ecd2e88719d1c",
            "bfd06be72cfc450ea63513364359a50e",
            "3247fa95f40a49368550eb4870770a54",
            "e7147c3e8a624a2f9e92a95f45564bb5",
            "41001e923fdf42f8bdd93d4a1616e6e1",
            "0971a7eb2f6943e09227bfebc2198277",
            "93a33f25b0ab44f48a0e97dcfdd6bb17",
            "cecab57ce9e14cad869a4e42564b4220",
            "127b7638de3446009177c6262fac364f",
            "3f1b2ca80b394f85a567c1d531a2fbe5",
            "0a8cd3f552e54965a563f226c78fdee1",
            "fdb07a7fac374d09982fab5032de4bd4",
            "2f22758e986a48cab10f3e30427d394d",
            "03c49218002946e8801c7ca3ab30c1b5",
            "c504b6860ef444d88703f4268c20edf4",
            "863a26528bdb4d978941f8403884f9e8",
            "5ddae26688db4789968a1ca0835c7da9",
            "a18586057e2045cd869dfe2cd1eb361a",
            "b4250e3e744e48f4a4788e107d82f26f",
            "f035f5b91f644a8085db021ab19ec7af",
            "b0e75d3dc3194eff8c55bd62375998f6",
            "ce5d731894d7453aad4f987ebc610259",
            "9edcc3fc9c3649aaa3817075a0528d5e",
            "9b97a69b12dd4ccd963cb61e6476aca9",
            "f2de459cb8184df39fbc1159a262b801",
            "f2dd8e8888a1409b8ab9f83fe44aa829",
            "e7b3d352a06644a0be4b097f0250861b",
            "1143bcbeb69a4714a3e04dd8ffa6a8d2",
            "becb35ec41524e6b90eba1b72cf7669e",
            "bd43d0677011485f910742dbd17a522c",
            "4ad878c092de4f81984f9b4514602923",
            "fca22cb2ae7b4f299f6a4c957670e08e",
            "2f778119d7734536a624bddc94d3d4ab",
            "eddb57aab3b64d17aa88214cc8796a75",
            "d4470e4e2b314036b65d3cb905d2296a",
            "6731c4bdb70a4ad2ad0e9c533239e7b9",
            "4eb6ea13a7fe4654a2ac175e9c53c200",
            "89f2514d59004d1cb095f86932da4ce1",
            "5cd1b6e83e2d4bf5817ede504b922b56",
            "78fec37ce3e44f4c87849a2c603f24e6",
            "c677574c31464198b31d384a2704837b",
            "a7936013adae4603bffde42a8d6c5e8b",
            "042946754ee0466f94ec75f51ce7856f",
            "b48dfd2f889a479b9fa575b8bf7fddfa",
            "a4a486cb0f654341a3d5c6912356d08c",
            "2bad50d5543142408e9e3f6fd64f66d5",
            "d33a339d66b9429cb1a6b7eb45f42d8b",
            "663b3c4be00e4bb9aeb55624af33db0d",
            "c46e9b73f6894640b13c7a82ff0424c2",
            "bd1f25959487476db6447bc23cac2986",
            "5583de191894416ca25205831d1b1bce",
            "377644efdc3346a6a387b83f150a1489",
            "6963e6d3a6df42e2a3281b76cd40a3df",
            "0bc433640dec46c9994bbc547987ab13",
            "251f4d809474410693e779645a86217f",
            "2db420b396d849ceb587737f23ac6f8b",
            "66cc806c49b646189afe6ac75a53f277",
            "76b1414ac2734c31904fe4495da4de11",
            "afdc54f17ac443d999e415e4530573da",
            "254b8a5c7b534db4aa1c3943ca7a6c54",
            "1b16aa06f09341c684147db341ab4d71",
            "bf25c31c274941f0bdd110e5c7613753",
            "80cee8c3f3fd488fa89f20eb38c87036",
            "ca27d2e8778d4c1188b8dbfd4efdec8c",
            "d73bf34b9e4c422b9c74b0f2b1eeacc4",
            "dbaee9939c2f411a90536b32ad05e9e5",
            "7901ff383b4544ecbce4d22a0a692502",
            "f14f20c0c0864285a206c062b563b8d4",
            "e4a6b66fd6444d3daa9b5bd8ae72fb95",
            "7680623e726e4a6486bdca477d219dd4",
            "3b3bdebe762b46d08824baf13701298d",
            "20e1b97577df4e868e7e4ec30d3d946d",
            "db3001ea29b5416b8ca5853800e86b8c",
            "17e66aded912448d85124ce9d58f0309",
            "866d2e3a867341e2896bdd1505f6eeaf",
            "14a6c38c17dd4d31bd25645a6330328a",
            "58a698e1e8be40dda2b9fee3e63ad785",
            "0ab7654c05b845e183512d5ae02dda44",
            "90ca05d3cc65452487d0fba0d41bd261",
            "21e57fd294ab4df89efffd4e9c1eb62a",
            "36fa3ef5ae2d43819702657b6e9d0faf",
            "d0481a09d3c64890b13bd13b643bafc3",
            "1894c211f52446d09d187db90413aded",
            "8bbdec77769048f4adc55ec99bfa0fde",
            "d27ccc9bbe584bc48e3cbf7284f63d85",
            "91b0933496264118bfbb050487e8fb92",
            "9e750706c4d94c8e81ccf523b3736315",
            "31acdaaa7a3246a28688646d36be100a",
            "5c6eebd050814b3aa1c36e30fd375822",
            "8c6584c966c140b4a6110ec400b80a16",
            "1f8919779476457e8055f9014d03de02",
            "87280179c281474fb20c0e8f17b22e71",
            "9d12046591bb48be98a5b587b1b8f993",
            "03c2d6633f504b89aa499210569f2c11",
            "1e04a780c35047949fc03797c63d7a53",
            "f5d9f3133cf9432998ad82d6b02c51aa",
            "746e4a65ae154470a8221bb8fb16382d",
            "f29c356307ca4c04a65046588cf030cb",
            "14bcb0d79b034b2991a23e563ec5edfa",
            "ef4bb53c71794d42b08ea5eff83c3dff",
            "d8a8c936b049419d889132f3fb038698",
            "bb3ce973963748a69bb2822f96c5a0c5",
            "d5455260b14a411ab8a43fdaa42fed74",
            "2634078caded4456a5c653edf07b516a",
            "71c9e6e0ca4b4eacb11e0b67df30f688"
          ]
        },
        "id": "sWPyaLsWo5ZQ",
        "outputId": "31be16e5-6879-4254-8723-173b355752a3"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import upload_folder, create_repo\n",
        "\n",
        "repo_id = create_repo(repo_id, exist_ok=True).repo_id\n",
        "\n",
        "\n",
        "upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    folder_path=output_dir,\n",
        "    commit_message=\"Pushed the IDEFICS2 fine-tuned model on some archae context sheets just to figure out the workflow.\",\n",
        "    ignore_patterns=[\"step_*\", \"epoch_*\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing things out on more data\n",
        "\n",
        "Below, we load some images the model hasn't seen, and then we try them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-BgAybQtO_k",
        "outputId": "b85c54e8-7361-4bc4-8ff7-2c2f872afe60"
      },
      "outputs": [],
      "source": [
        "!unzip random-images.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj8V9UnItlqw"
      },
      "outputs": [],
      "source": [
        "#Mac users, if you see a bunch of filenames starting with a period, we can clean\n",
        "#those out with this code:\n",
        "#remove dot files in the folder random-images\n",
        "\n",
        "import os\n",
        "\n",
        "def remove_dot_files(directory):\n",
        "  for filename in os.listdir(directory):\n",
        "    if filename.startswith('.'):\n",
        "      filepath = os.path.join(directory, filename)\n",
        "      try:\n",
        "        if os.path.isfile(filepath):\n",
        "          os.remove(filepath)\n",
        "        elif os.path.isdir(filepath):\n",
        "          # Handle directories if needed (e.g., recursively remove contents)\n",
        "          # For simplicity, this example only removes files.\n",
        "          pass\n",
        "        print(f\"Removed: {filepath}\")\n",
        "      except OSError as e:\n",
        "        print(f\"Error removing {filepath}: {e}\")\n",
        "\n",
        "remove_dot_files(\"random-images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtSicRmosom6"
      },
      "outputs": [],
      "source": [
        "from PIL import Image #Import from PIL, not datasets\n",
        "\n",
        "\n",
        "## a function to let you ask one question at a time of the images.\n",
        "## ugly, but ok\n",
        "\n",
        "def process_new_images(model, processor, image_dir):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith(\".jpg\"):  ## pay attention to file endings! Should modify this for multiple file types\n",
        "            filepath = os.path.join(image_dir, filename)\n",
        "            try:\n",
        "                # Correctly open the image using PIL\n",
        "                image = Image.open(filepath).convert(\"RGB\")\n",
        "                query = input(f\"Enter question for {filename}: \")  #Get question from user\n",
        "                messages = [\n",
        "                    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Give your best answer.\"}, {\"type\": \"image\"}, {\"type\": \"text\", \"text\": query}]}\n",
        "                ]\n",
        "                text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "                inputs = processor(text=[text.strip()], images=[image], return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "                generated_ids = model.generate(**inputs, max_new_tokens=64)\n",
        "                generated_texts = processor.batch_decode(generated_ids[:, inputs[\"input_ids\"].size(1):], skip_special_tokens=True)\n",
        "                print(f\"Answer for {filename}: {generated_texts[0]}\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: Image file not found: {filepath}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whsV1_mztdN3",
        "outputId": "f8f30e61-6b3e-47d8-b65b-6381a1c4a6f2"
      },
      "outputs": [],
      "source": [
        "# When you run this, it will iterate over each file in your random-images folder\n",
        "# giving you a query box into which you may type your question\n",
        "# ie, What is the nature of the soil?\n",
        "process_new_images(model, processor, \"/content/random-images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0aWrvgszdEu",
        "outputId": "c33318ed-4757-44fc-a582-5d38a137d8c8"
      },
      "outputs": [],
      "source": [
        "## a function to ask the same question of every image in a folder\n",
        "\n",
        "def process_images(model, processor, image_dir, question):\n",
        "    all_answers = {} #Use a dictionary to store answers with filenames as keys.\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith(\".jpg\"): ### file endings!!\n",
        "            filepath = os.path.join(image_dir, filename)\n",
        "            try:\n",
        "                image = Image.open(filepath).convert(\"RGB\")\n",
        "                messages = [\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            {\"type\": \"text\", \"text\": f\"Give your best answer to the following question: '{question}'\"},\n",
        "                            {\"type\": \"image\"},\n",
        "                        ]\n",
        "                    }\n",
        "                ]\n",
        "                text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "                inputs = processor(text=[text.strip()], images=[image], return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "                generated_ids = model.generate(**inputs, max_new_tokens=64)\n",
        "                generated_texts = processor.batch_decode(generated_ids[:, inputs[\"input_ids\"].size(1):], skip_special_tokens=True)\n",
        "                all_answers[filename] = generated_texts[0] #Store answer with filename\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "                all_answers[filename] = f\"Error processing {filename}: {e}\" #Store error message\n",
        "\n",
        "    return all_answers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do it\n",
        "image_directory = \"/content/random-images\"\n",
        "question_to_ask = \"Identify the stratigraphic relationships present\"\n",
        "individual_answers = process_images(model, processor, image_directory, question_to_ask)\n",
        "\n",
        "# Print the answers\n",
        "for filename, answer in individual_answers.items():\n",
        "    print(f\"\\nImage: {filename}\\nAnswer: {answer}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}